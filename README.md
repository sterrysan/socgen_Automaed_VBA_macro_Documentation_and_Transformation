# socgen_Automaed_VBA_macro_Documentation_and_Transformation

### Download and install the required libraries using
pip install transformers torch
pip install graphviz gpt4all
pip install gradio

Then run the given python code in local or in google collab
-If you planned to run in local machine, make sure high end gpu and cpu with suffiecient ram and storage is installed in the machine. Because LLAMA 3 8b model is resource intensive.
-If you planned to run in google collab, tweak "max_tokens" based on the need to reduce execution time.


##high 'max_tokens' -> gives larger detailed explanation (takes time)
##less 'max_tokens' -> gives smaller explanation (faster)

Even LLAMA 3 with 70B parameters can be used for more accurate results. But only thing we need is significant hardware resource.

Sorry for addressing few things later. The whole project's mechanism was created on time. I got very low end device(4gb ram + AMD A4 processor) , so...
Please take a look into demo video recorded to see the working of this automation tool created.

#Google collab notebook
https://colab.research.google.com/drive/1PQB0efH_F730BXaeioLvx74XmcynVCMs?usp=sharing

For any queries in implementing this
Mail: d22z606@psgitech.ac.in / santhoshs4048@gmail.com
